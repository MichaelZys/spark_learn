{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SparkSession创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 一、导入\n",
    "##### 导入后类型都是DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接导入\n",
    "df = spark.read.load(\"examples/src/main/resources/users.parquet\")\n",
    "# 指定格式导入\n",
    "df = spark.read.load(\"examples/src/main/resources/people.json\", format=\"json\")\n",
    "# 指定格式和参数导入\n",
    "df = spark.read.load(\"examples/src/main/resources/people.csv\",\\\n",
    "                     format=\"csv\", sep=\":\", inferSchema=\"true\", header=\"true\")\n",
    "# 导入orc\n",
    "df = spark.read.orc(\"examples/src/main/resources/users.orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 二、导出\n",
    "##### mode参数控制文件保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# mode = ['error'(有就报错), 'append'(追加), 'overwrite'(覆盖), 'ignore'(忽略)]\n",
    "# 直接保存\n",
    "df.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")\n",
    "# 指定格式保存\n",
    "df.select(\"name\", \"age\").write.save(\"namesAndAges.parquet\", format=\"parquet\")\n",
    "# orc保存\n",
    "(df.write.format(\"orc\")\n",
    "    .option(\"orc.bloom.filter.columns\", \"favorite_color\")\n",
    "    .option(\"orc.dictionary.key.threshold\", \"1.0\")\n",
    "    .save(\"users_with_options.orc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 三、持久化到表\n",
    "##### 3.1 持久化到表后，再次重启Session都还有数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option('path', '/some/path').saveAsTable('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Bucketing, Sorting and Partitioning后持久化到表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketing and sorting are applicable only to persistent tables\n",
    "df.write.bucketBy(42, \"name\").sortBy(\"age\").saveAsTable(\"people_bucketed\")\n",
    "df.write.partitionBy(\"favorite_color\").format(\"parquet\").save(\"namesPartByColor.parquet\")\n",
    "\n",
    "(df.write.partitionBy(\"favorite_color\")\\\n",
    "         .bucketBy(42, \"name\")\\\n",
    "         .saveAsTable(\"people_partitioned_bucketed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 删除表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS people_bucketed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
